{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eaf10429-8d69-4a7b-8dfa-524e628d2f5e",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f5a6b42-ab2e-4328-8b3b-bf8129e3877d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "sampled_data = pd.read_csv('../data/final_train_data.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48786168-42be-4038-84dc-61578bee581e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b883c534-dfa8-4584-b2a3-5de6ef84976d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>asin</th>\n",
       "      <th>title</th>\n",
       "      <th>price</th>\n",
       "      <th>userId</th>\n",
       "      <th>profileName</th>\n",
       "      <th>reviewHelpfulness</th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewSummary</th>\n",
       "      <th>...</th>\n",
       "      <th>text_lematized</th>\n",
       "      <th>length</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>total_length</th>\n",
       "      <th>num_exclamation_marks</th>\n",
       "      <th>num_question_marks</th>\n",
       "      <th>num_punctuation</th>\n",
       "      <th>num_symbols</th>\n",
       "      <th>mapped_sentiment</th>\n",
       "      <th>lengths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1882931173</td>\n",
       "      <td>Its Only Art If Its Well Hung!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AVCGYZL8FQQTD</td>\n",
       "      <td>Jim of Oz \"jim-of-oz\"</td>\n",
       "      <td>7/7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>940636800</td>\n",
       "      <td>Nice collection of Julie Strain images</td>\n",
       "      <td>...</td>\n",
       "      <td>this be only for julie strain fan . it ' s a c...</td>\n",
       "      <td>463</td>\n",
       "      <td>positive</td>\n",
       "      <td>463</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0826414346</td>\n",
       "      <td>Dr. Seuss: American Icon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A30TK6U7DNS82R</td>\n",
       "      <td>Kevin Killian</td>\n",
       "      <td>10/10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1095724800</td>\n",
       "      <td>Really Enjoyed It</td>\n",
       "      <td>...</td>\n",
       "      <td>i do not care much for dr. seuss but after rea...</td>\n",
       "      <td>1435</td>\n",
       "      <td>positive</td>\n",
       "      <td>1435</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0826414346</td>\n",
       "      <td>Dr. Seuss: American Icon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A3UH4UZ4RSVO82</td>\n",
       "      <td>John Granger</td>\n",
       "      <td>10/11</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1078790400</td>\n",
       "      <td>Essential for every personal and Public Library</td>\n",
       "      <td>...</td>\n",
       "      <td>if people become the book they read and if \" t...</td>\n",
       "      <td>1763</td>\n",
       "      <td>positive</td>\n",
       "      <td>1763</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0826414346</td>\n",
       "      <td>Dr. Seuss: American Icon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A22X4XUPKF66MR</td>\n",
       "      <td>D. H. Richards \"ninthwavestore\"</td>\n",
       "      <td>3/3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1107993600</td>\n",
       "      <td>Good academic overview</td>\n",
       "      <td>...</td>\n",
       "      <td>philip nel - dr. seuss : american icon this be...</td>\n",
       "      <td>1552</td>\n",
       "      <td>positive</td>\n",
       "      <td>1552</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0826414346</td>\n",
       "      <td>Dr. Seuss: American Icon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A2F6NONFUDB6UK</td>\n",
       "      <td>Malvin</td>\n",
       "      <td>2/2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1127174400</td>\n",
       "      <td>One of America's greatest creative talents</td>\n",
       "      <td>...</td>\n",
       "      <td>\" dr . seuss : american icon \" by philip nel b...</td>\n",
       "      <td>1988</td>\n",
       "      <td>positive</td>\n",
       "      <td>1988</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128642</th>\n",
       "      <td>128642</td>\n",
       "      <td>B0007PC4ZM</td>\n",
       "      <td>Collapse: How Societies Choose to Fail or Succeed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A26ZAM8KFU0GY9</td>\n",
       "      <td>Jim Estill</td>\n",
       "      <td>0/2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1155081600</td>\n",
       "      <td>How to Thrive</td>\n",
       "      <td>...</td>\n",
       "      <td>i read collapse by jared diamond . this be an ...</td>\n",
       "      <td>524</td>\n",
       "      <td>positive</td>\n",
       "      <td>524</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128643</th>\n",
       "      <td>128643</td>\n",
       "      <td>B0007PC4ZM</td>\n",
       "      <td>Collapse: How Societies Choose to Fail or Succeed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A3KKUNIFVEAHNC</td>\n",
       "      <td>saskatoonguy</td>\n",
       "      <td>7/14</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1143244800</td>\n",
       "      <td>Intriguing bits of world history plus sky-is-f...</td>\n",
       "      <td>...</td>\n",
       "      <td>most of this book consist of story of fail soc...</td>\n",
       "      <td>1709</td>\n",
       "      <td>negative</td>\n",
       "      <td>1709</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128644</th>\n",
       "      <td>128644</td>\n",
       "      <td>B0007PC4ZM</td>\n",
       "      <td>Collapse: How Societies Choose to Fail or Succeed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A1ALF72BQ4RIEL</td>\n",
       "      <td>Bill Pen Name</td>\n",
       "      <td>4/9</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1137024000</td>\n",
       "      <td>A Must Read for all Thoughtful People</td>\n",
       "      <td>...</td>\n",
       "      <td>this work would rate at the top of the scale j...</td>\n",
       "      <td>258</td>\n",
       "      <td>positive</td>\n",
       "      <td>258</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128645</th>\n",
       "      <td>128645</td>\n",
       "      <td>B0007PC4ZM</td>\n",
       "      <td>Collapse: How Societies Choose to Fail or Succeed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A1ZS0YNUQ4UAJ2</td>\n",
       "      <td>Susan Norton</td>\n",
       "      <td>4/9</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1107561600</td>\n",
       "      <td>Full of interest</td>\n",
       "      <td>...</td>\n",
       "      <td>i be not sure if i agree with everything in th...</td>\n",
       "      <td>415</td>\n",
       "      <td>positive</td>\n",
       "      <td>415</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128646</th>\n",
       "      <td>128646</td>\n",
       "      <td>B0007PC4ZM</td>\n",
       "      <td>Collapse: How Societies Choose to Fail or Succeed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A3ELVZ6MUXSSBA</td>\n",
       "      <td>Kathryn Murdock \"coastal kate\"</td>\n",
       "      <td>14/26</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1120694400</td>\n",
       "      <td>Collapse</td>\n",
       "      <td>...</td>\n",
       "      <td>i be disappoint . too long by several hundred ...</td>\n",
       "      <td>322</td>\n",
       "      <td>mixed</td>\n",
       "      <td>322</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>128647 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0        asin  \\\n",
       "0                0  1882931173   \n",
       "1                1  0826414346   \n",
       "2                2  0826414346   \n",
       "3                3  0826414346   \n",
       "4                4  0826414346   \n",
       "...            ...         ...   \n",
       "128642      128642  B0007PC4ZM   \n",
       "128643      128643  B0007PC4ZM   \n",
       "128644      128644  B0007PC4ZM   \n",
       "128645      128645  B0007PC4ZM   \n",
       "128646      128646  B0007PC4ZM   \n",
       "\n",
       "                                                    title  price  \\\n",
       "0                          Its Only Art If Its Well Hung!    NaN   \n",
       "1                                Dr. Seuss: American Icon    NaN   \n",
       "2                                Dr. Seuss: American Icon    NaN   \n",
       "3                                Dr. Seuss: American Icon    NaN   \n",
       "4                                Dr. Seuss: American Icon    NaN   \n",
       "...                                                   ...    ...   \n",
       "128642  Collapse: How Societies Choose to Fail or Succeed    NaN   \n",
       "128643  Collapse: How Societies Choose to Fail or Succeed    NaN   \n",
       "128644  Collapse: How Societies Choose to Fail or Succeed    NaN   \n",
       "128645  Collapse: How Societies Choose to Fail or Succeed    NaN   \n",
       "128646  Collapse: How Societies Choose to Fail or Succeed    NaN   \n",
       "\n",
       "                userId                      profileName reviewHelpfulness  \\\n",
       "0        AVCGYZL8FQQTD            Jim of Oz \"jim-of-oz\"               7/7   \n",
       "1       A30TK6U7DNS82R                    Kevin Killian             10/10   \n",
       "2       A3UH4UZ4RSVO82                     John Granger             10/11   \n",
       "3       A22X4XUPKF66MR  D. H. Richards \"ninthwavestore\"               3/3   \n",
       "4       A2F6NONFUDB6UK                           Malvin               2/2   \n",
       "...                ...                              ...               ...   \n",
       "128642  A26ZAM8KFU0GY9                       Jim Estill               0/2   \n",
       "128643  A3KKUNIFVEAHNC                     saskatoonguy              7/14   \n",
       "128644  A1ALF72BQ4RIEL                    Bill Pen Name               4/9   \n",
       "128645  A1ZS0YNUQ4UAJ2                     Susan Norton               4/9   \n",
       "128646  A3ELVZ6MUXSSBA   Kathryn Murdock \"coastal kate\"             14/26   \n",
       "\n",
       "        overall  reviewTime  \\\n",
       "0           4.0   940636800   \n",
       "1           5.0  1095724800   \n",
       "2           5.0  1078790400   \n",
       "3           4.0  1107993600   \n",
       "4           4.0  1127174400   \n",
       "...         ...         ...   \n",
       "128642      4.0  1155081600   \n",
       "128643      2.0  1143244800   \n",
       "128644      5.0  1137024000   \n",
       "128645      5.0  1107561600   \n",
       "128646      3.0  1120694400   \n",
       "\n",
       "                                            reviewSummary  ...  \\\n",
       "0                  Nice collection of Julie Strain images  ...   \n",
       "1                                       Really Enjoyed It  ...   \n",
       "2         Essential for every personal and Public Library  ...   \n",
       "3                                  Good academic overview  ...   \n",
       "4              One of America's greatest creative talents  ...   \n",
       "...                                                   ...  ...   \n",
       "128642                                      How to Thrive  ...   \n",
       "128643  Intriguing bits of world history plus sky-is-f...  ...   \n",
       "128644              A Must Read for all Thoughtful People  ...   \n",
       "128645                                   Full of interest  ...   \n",
       "128646                                           Collapse  ...   \n",
       "\n",
       "                                           text_lematized length sentiment  \\\n",
       "0       this be only for julie strain fan . it ' s a c...    463  positive   \n",
       "1       i do not care much for dr. seuss but after rea...   1435  positive   \n",
       "2       if people become the book they read and if \" t...   1763  positive   \n",
       "3       philip nel - dr. seuss : american icon this be...   1552  positive   \n",
       "4       \" dr . seuss : american icon \" by philip nel b...   1988  positive   \n",
       "...                                                   ...    ...       ...   \n",
       "128642  i read collapse by jared diamond . this be an ...    524  positive   \n",
       "128643  most of this book consist of story of fail soc...   1709  negative   \n",
       "128644  this work would rate at the top of the scale j...    258  positive   \n",
       "128645  i be not sure if i agree with everything in th...    415  positive   \n",
       "128646  i be disappoint . too long by several hundred ...    322     mixed   \n",
       "\n",
       "        total_length num_exclamation_marks  num_question_marks  \\\n",
       "0                463                     0                   0   \n",
       "1               1435                     1                   0   \n",
       "2               1763                     2                   0   \n",
       "3               1552                     0                   1   \n",
       "4               1988                     0                   0   \n",
       "...              ...                   ...                 ...   \n",
       "128642           524                     0                   0   \n",
       "128643          1709                     0                   1   \n",
       "128644           258                     0                   0   \n",
       "128645           415                     0                   0   \n",
       "128646           322                     0                   0   \n",
       "\n",
       "        num_punctuation  num_symbols  mapped_sentiment  lengths  \n",
       "0                    11            0                 2       93  \n",
       "1                    22            0                 2      264  \n",
       "2                    28            0                 2      321  \n",
       "3                    27            0                 2      286  \n",
       "4                    29            0                 2      312  \n",
       "...                 ...          ...               ...      ...  \n",
       "128642                6            0                 2       94  \n",
       "128643               20            2                 0      293  \n",
       "128644                3            0                 2       50  \n",
       "128645                6            0                 2       79  \n",
       "128646                6            0                 1       56  \n",
       "\n",
       "[128647 rows x 22 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fff00d83-765a-446e-a46f-47a0a30f30e0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== 102917\n",
      "[2024-08-15 15:58:32,544] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-08-15 15:58:33,910] [WARNING] [runner.py:202:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.\n",
      "[2024-08-15 15:58:33,927] [INFO] [runner.py:571:main] cmd = /media/veracrypt4/repos/intro-to-supervised-algorithms-in-machine-learning-final-project/venv/bin/python3.10 -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMF19 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None run_transformer_training.py --deepspeed model_config_gpt_contentyze.json --model_name_or_path xlnet-base-cased --train_file data/data_train_sampled_for_drill_temp0.csv --validation_file data/data_test_sampled_for_drill_temp0.csv --do_train --do_eval --report_to wandb --overwrite_cache --output_dir /model_saved/model_trained0/ --num_train_epochs 1 --gradient_accumulation_steps 16 --per_device_train_batch_size 48 --use_fast_tokenizer False --learning_rate 5e-06 --logging_steps=1 --save_steps=200\n",
      "[2024-08-15 15:58:34,852] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-08-15 15:58:36,009] [INFO] [launch.py:145:main] WORLD INFO DICT: {'localhost': [0]}\n",
      "[2024-08-15 15:58:36,009] [INFO] [launch.py:151:main] nnodes=1, num_local_procs=1, node_rank=0\n",
      "[2024-08-15 15:58:36,009] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})\n",
      "[2024-08-15 15:58:36,009] [INFO] [launch.py:163:main] dist_world_size=1\n",
      "[2024-08-15 15:58:36,009] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0\n",
      "/media/veracrypt4/repos/intro-to-supervised-algorithms-in-machine-learning-final-project/venv/bin/python3.10: can't open file '/media/veracrypt4/repos/intro-to-supervised-algorithms-in-machine-learning-final-project/notebooks/run_transformer_training.py': [Errno 2] No such file or directory\n",
      "[2024-08-15 15:58:37,011] [INFO] [launch.py:315:sigkill_handler] Killing subprocess 68620\n",
      "[2024-08-15 15:58:37,011] [ERROR] [launch.py:321:sigkill_handler] ['/media/veracrypt4/repos/intro-to-supervised-algorithms-in-machine-learning-final-project/venv/bin/python3.10', '-u', 'run_transformer_training.py', '--local_rank=0', '--deepspeed', 'model_config_gpt_contentyze.json', '--model_name_or_path', 'xlnet-base-cased', '--train_file', 'data/data_train_sampled_for_drill_temp0.csv', '--validation_file', 'data/data_test_sampled_for_drill_temp0.csv', '--do_train', '--do_eval', '--report_to', 'wandb', '--overwrite_cache', '--output_dir', '/model_saved/model_trained0/', '--num_train_epochs', '1', '--gradient_accumulation_steps', '16', '--per_device_train_batch_size', '48', '--use_fast_tokenizer', 'False', '--learning_rate', '5e-06', '--logging_steps=1', '--save_steps=200'] exits with return code = 2\n",
      "====== 102917\n",
      "[2024-08-15 15:58:41,891] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-08-15 15:58:42,977] [WARNING] [runner.py:202:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.\n",
      "[2024-08-15 15:58:42,993] [INFO] [runner.py:571:main] cmd = /media/veracrypt4/repos/intro-to-supervised-algorithms-in-machine-learning-final-project/venv/bin/python3.10 -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMF19 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None run_transformer_training.py --deepspeed model_config_gpt_contentyze.json --model_name_or_path xlnet-base-cased --train_file data/data_train_sampled_for_drill_temp1.csv --validation_file data/data_test_sampled_for_drill_temp1.csv --do_train --do_eval --report_to wandb --overwrite_cache --output_dir /model_saved/model_trained1/ --num_train_epochs 1 --gradient_accumulation_steps 16 --per_device_train_batch_size 48 --use_fast_tokenizer False --learning_rate 5e-06 --logging_steps=1 --save_steps=200\n",
      "[2024-08-15 15:58:43,932] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-08-15 15:58:45,030] [INFO] [launch.py:145:main] WORLD INFO DICT: {'localhost': [0]}\n",
      "[2024-08-15 15:58:45,031] [INFO] [launch.py:151:main] nnodes=1, num_local_procs=1, node_rank=0\n",
      "[2024-08-15 15:58:45,031] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})\n",
      "[2024-08-15 15:58:45,031] [INFO] [launch.py:163:main] dist_world_size=1\n",
      "[2024-08-15 15:58:45,031] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0\n",
      "/media/veracrypt4/repos/intro-to-supervised-algorithms-in-machine-learning-final-project/venv/bin/python3.10: can't open file '/media/veracrypt4/repos/intro-to-supervised-algorithms-in-machine-learning-final-project/notebooks/run_transformer_training.py': [Errno 2] No such file or directory\n",
      "[2024-08-15 15:58:46,031] [INFO] [launch.py:315:sigkill_handler] Killing subprocess 68724\n",
      "[2024-08-15 15:58:46,031] [ERROR] [launch.py:321:sigkill_handler] ['/media/veracrypt4/repos/intro-to-supervised-algorithms-in-machine-learning-final-project/venv/bin/python3.10', '-u', 'run_transformer_training.py', '--local_rank=0', '--deepspeed', 'model_config_gpt_contentyze.json', '--model_name_or_path', 'xlnet-base-cased', '--train_file', 'data/data_train_sampled_for_drill_temp1.csv', '--validation_file', 'data/data_test_sampled_for_drill_temp1.csv', '--do_train', '--do_eval', '--report_to', 'wandb', '--overwrite_cache', '--output_dir', '/model_saved/model_trained1/', '--num_train_epochs', '1', '--gradient_accumulation_steps', '16', '--per_device_train_batch_size', '48', '--use_fast_tokenizer', 'False', '--learning_rate', '5e-06', '--logging_steps=1', '--save_steps=200'] exits with return code = 2\n",
      "====== 102918\n",
      "[2024-08-15 15:58:50,976] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-08-15 15:58:52,095] [WARNING] [runner.py:202:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.\n",
      "[2024-08-15 15:58:52,112] [INFO] [runner.py:571:main] cmd = /media/veracrypt4/repos/intro-to-supervised-algorithms-in-machine-learning-final-project/venv/bin/python3.10 -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMF19 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None run_transformer_training.py --deepspeed model_config_gpt_contentyze.json --model_name_or_path xlnet-base-cased --train_file data/data_train_sampled_for_drill_temp2.csv --validation_file data/data_test_sampled_for_drill_temp2.csv --do_train --do_eval --report_to wandb --overwrite_cache --output_dir /model_saved/model_trained2/ --num_train_epochs 1 --gradient_accumulation_steps 16 --per_device_train_batch_size 48 --use_fast_tokenizer False --learning_rate 5e-06 --logging_steps=1 --save_steps=200\n",
      "[2024-08-15 15:58:53,054] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-08-15 15:58:54,172] [INFO] [launch.py:145:main] WORLD INFO DICT: {'localhost': [0]}\n",
      "[2024-08-15 15:58:54,172] [INFO] [launch.py:151:main] nnodes=1, num_local_procs=1, node_rank=0\n",
      "[2024-08-15 15:58:54,172] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})\n",
      "[2024-08-15 15:58:54,172] [INFO] [launch.py:163:main] dist_world_size=1\n",
      "[2024-08-15 15:58:54,172] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0\n",
      "/media/veracrypt4/repos/intro-to-supervised-algorithms-in-machine-learning-final-project/venv/bin/python3.10: can't open file '/media/veracrypt4/repos/intro-to-supervised-algorithms-in-machine-learning-final-project/notebooks/run_transformer_training.py': [Errno 2] No such file or directory\n",
      "[2024-08-15 15:58:55,173] [INFO] [launch.py:315:sigkill_handler] Killing subprocess 68835\n",
      "[2024-08-15 15:58:55,174] [ERROR] [launch.py:321:sigkill_handler] ['/media/veracrypt4/repos/intro-to-supervised-algorithms-in-machine-learning-final-project/venv/bin/python3.10', '-u', 'run_transformer_training.py', '--local_rank=0', '--deepspeed', 'model_config_gpt_contentyze.json', '--model_name_or_path', 'xlnet-base-cased', '--train_file', 'data/data_train_sampled_for_drill_temp2.csv', '--validation_file', 'data/data_test_sampled_for_drill_temp2.csv', '--do_train', '--do_eval', '--report_to', 'wandb', '--overwrite_cache', '--output_dir', '/model_saved/model_trained2/', '--num_train_epochs', '1', '--gradient_accumulation_steps', '16', '--per_device_train_batch_size', '48', '--use_fast_tokenizer', 'False', '--learning_rate', '5e-06', '--logging_steps=1', '--save_steps=200'] exits with return code = 2\n",
      "====== 102918\n",
      "[2024-08-15 15:59:00,259] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-08-15 15:59:01,356] [WARNING] [runner.py:202:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.\n",
      "[2024-08-15 15:59:01,372] [INFO] [runner.py:571:main] cmd = /media/veracrypt4/repos/intro-to-supervised-algorithms-in-machine-learning-final-project/venv/bin/python3.10 -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMF19 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None run_transformer_training.py --deepspeed model_config_gpt_contentyze.json --model_name_or_path xlnet-base-cased --train_file data/data_train_sampled_for_drill_temp3.csv --validation_file data/data_test_sampled_for_drill_temp3.csv --do_train --do_eval --report_to wandb --overwrite_cache --output_dir /model_saved/model_trained3/ --num_train_epochs 1 --gradient_accumulation_steps 16 --per_device_train_batch_size 48 --use_fast_tokenizer False --learning_rate 5e-06 --logging_steps=1 --save_steps=200\n",
      "[2024-08-15 15:59:02,320] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-08-15 15:59:03,416] [INFO] [launch.py:145:main] WORLD INFO DICT: {'localhost': [0]}\n",
      "[2024-08-15 15:59:03,416] [INFO] [launch.py:151:main] nnodes=1, num_local_procs=1, node_rank=0\n",
      "[2024-08-15 15:59:03,416] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})\n",
      "[2024-08-15 15:59:03,416] [INFO] [launch.py:163:main] dist_world_size=1\n",
      "[2024-08-15 15:59:03,417] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0\n",
      "/media/veracrypt4/repos/intro-to-supervised-algorithms-in-machine-learning-final-project/venv/bin/python3.10: can't open file '/media/veracrypt4/repos/intro-to-supervised-algorithms-in-machine-learning-final-project/notebooks/run_transformer_training.py': [Errno 2] No such file or directory\n",
      "[2024-08-15 15:59:04,418] [INFO] [launch.py:315:sigkill_handler] Killing subprocess 68949\n",
      "[2024-08-15 15:59:04,418] [ERROR] [launch.py:321:sigkill_handler] ['/media/veracrypt4/repos/intro-to-supervised-algorithms-in-machine-learning-final-project/venv/bin/python3.10', '-u', 'run_transformer_training.py', '--local_rank=0', '--deepspeed', 'model_config_gpt_contentyze.json', '--model_name_or_path', 'xlnet-base-cased', '--train_file', 'data/data_train_sampled_for_drill_temp3.csv', '--validation_file', 'data/data_test_sampled_for_drill_temp3.csv', '--do_train', '--do_eval', '--report_to', 'wandb', '--overwrite_cache', '--output_dir', '/model_saved/model_trained3/', '--num_train_epochs', '1', '--gradient_accumulation_steps', '16', '--per_device_train_batch_size', '48', '--use_fast_tokenizer', 'False', '--learning_rate', '5e-06', '--logging_steps=1', '--save_steps=200'] exits with return code = 2\n",
      "====== 102918\n",
      "[2024-08-15 15:59:09,487] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-08-15 15:59:10,639] [WARNING] [runner.py:202:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.\n",
      "[2024-08-15 15:59:10,656] [INFO] [runner.py:571:main] cmd = /media/veracrypt4/repos/intro-to-supervised-algorithms-in-machine-learning-final-project/venv/bin/python3.10 -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMF19 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None run_transformer_training.py --deepspeed model_config_gpt_contentyze.json --model_name_or_path xlnet-base-cased --train_file data/data_train_sampled_for_drill_temp4.csv --validation_file data/data_test_sampled_for_drill_temp4.csv --do_train --do_eval --report_to wandb --overwrite_cache --output_dir /model_saved/model_trained4/ --num_train_epochs 1 --gradient_accumulation_steps 16 --per_device_train_batch_size 48 --use_fast_tokenizer False --learning_rate 5e-06 --logging_steps=1 --save_steps=200\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "for fold, (train_ids, test_ids) in enumerate(cv.split(sampled_data.reviewText, sampled_data['sentiment'])):\n",
    "    print('======', len(train_ids))\n",
    "    sampled_data.loc[train_ids].to_csv(f'data/data_train_sampled_for_drill_temp{fold}.csv')\n",
    "    sampled_data.loc[test_ids].to_csv(f'data/data_test_sampled_for_drill_temp{fold}.csv')\n",
    "    !export MKL_SERVICE_FORCE_INTEL=1; deepspeed --num_gpus=1 \\\n",
    "           --num_nodes=1 \\\n",
    "           run_transformer_training.py \\\n",
    "           --deepspeed model_config_gpt_contentyze.json \\\n",
    "            --model_name_or_path 'xlnet-base-cased' \\\n",
    "            --train_file data/data_train_sampled_for_drill_temp{fold}.csv \\\n",
    "            --validation_file data/data_test_sampled_for_drill_temp{fold}.csv \\\n",
    "            --do_train \\\n",
    "            --do_eval \\\n",
    "            --report_to wandb \\\n",
    "            --overwrite_cache \\\n",
    "            --output_dir /model_saved/model_trained{fold}/ \\\n",
    "            --num_train_epochs  1  \\\n",
    "            --gradient_accumulation_steps 16  \\\n",
    "            --per_device_train_batch_size 48 \\\n",
    "            --use_fast_tokenizer False      \\\n",
    "            --learning_rate 5e-06 \\\n",
    "            --logging_steps=1 \\\n",
    "            --save_steps=200\n",
    "    !rm data/data_train_sampled_for_drill_temp{fold}.csv\n",
    "#             --fp16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "170edf76-2795-40d0-927f-04bfce17334a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from amazon_sentiment_analysis_model import AmazonSentimentReviewModel\n",
    "from transformers import XLNetTokenizer\n",
    "from datasets import load_dataset\n",
    "from run_transformer_training import tokenize_function, group_texts\n",
    "import os\n",
    "def load_model_from_path(path):\n",
    "    model = AmazonSentimentReviewModel()\n",
    "    model_state_dict = torch.load(os.path.join(path, 'pytorch_model.bin'))\n",
    "    model.load_state_dict(model_state_dict)\n",
    "    model = model.cuda().eval().half()\n",
    "    return model\n",
    "\n",
    "    \n",
    "def load_dataset_from_path(path):\n",
    "\n",
    "    datasets = load_dataset('csv', data_files=[path])\n",
    "    to_remove = [i for i in datasets.column_names['train'] if i not in ['overall', 'mapped_sentiment']]\n",
    "    column_names = datasets[\"train\"].column_names\n",
    "\n",
    "    text_column_name = 'reviewText'\n",
    "    tokenized_datasets = datasets.map(\n",
    "        lambda x: tokenize_function(x, tokenizer=tokenizer, text_column_name=text_column_name),\n",
    "\n",
    "        batched=True,\n",
    "        num_proc=1,\n",
    "        remove_columns=column_names,\n",
    "        load_from_cache_file=True,\n",
    "    )\n",
    "\n",
    "    lm_datasets = tokenized_datasets.map(\n",
    "        group_texts,\n",
    "        batched=True,\n",
    "        num_proc=1,\n",
    "        load_from_cache_file=True,\n",
    "    )\n",
    "    return lm_datasets\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e80605a-73a5-47c7-b55f-6b8c91ac14bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = XLNetTokenizer.from_pretrained(\"xlnet-large-cased\")\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84b8d4bd-0e02-46e0-a02a-9c045442cf71",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48a898a7-b480-4f7e-8a47-8e4f31ba3d65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc \n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2a3ba565-08e4-45fc-9e1a-f80413e44cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAPPING = {\n",
    "    0: \"neutral\",\n",
    "    1: \"negative\",\n",
    "    2: \"positive\"\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fcf44af3-3a97-4fe6-95d6-342bc1d81554",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n",
      "- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary.summary.weight', 'sequence_summary.summary.bias', 'logits_proj.bias', 'logits_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using custom data configuration default-36bbef79f8f67149\n",
      "Reusing dataset csv (/root/.cache/huggingface/datasets/csv/default-36bbef79f8f67149/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0)\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-36bbef79f8f67149/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0/cache-e61fb2b6290d7359.arrow\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-36bbef79f8f67149/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0/cache-6cbce7a8db5743db.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 SCORE: 0.7413247778219922\n",
      "\n",
      "F1 SCORE: 0.7461745585413458\n",
      "\n",
      "F1 SCORE: 0.748442304558527\n",
      "\n",
      "F1 SCORE: 0.7545019067898038\n",
      "\n",
      "F1 SCORE: 0.754092580889097\n",
      "\n",
      "F1 SCORE: 0.7547631769851101\n",
      "\n",
      "F1 SCORE: 0.7515443587895044\n",
      "\n",
      "F1 SCORE: 0.7505385409085439\n",
      "\n",
      "F1 SCORE: 0.7486612498133688\n",
      "\n",
      "F1 SCORE: 0.7477341464003349\n",
      "\n",
      "F1 SCORE: 0.7474489552114598\n",
      "\n",
      "F1 SCORE: 0.7467809074899913\n",
      "\n",
      "F1 SCORE: 0.7436606156344383\n",
      "\n",
      "F1 SCORE: 0.7417933593145448\n",
      "\n",
      "F1 SCORE: 0.7424124953825643\n",
      "\n",
      "F1 SCORE: 0.7416219254675522\n",
      "\n",
      "F1 SCORE: 0.7421186755969726\n",
      "\n",
      "F1 SCORE: 0.742056758329871\n",
      "\n",
      "F1 SCORE: 0.742122305234509\n",
      "\n",
      "F1 SCORE: 0.7410013494523106\n",
      "\n",
      "F1 SCORE: 0.7411502491020449\n",
      "\n",
      "F1 SCORE: 0.7416925181778983\n",
      "\n",
      "F1 SCORE: 0.7418906980631463\n",
      "\n",
      "F1 SCORE: 0.741721616039735\n",
      "\n",
      "F1 SCORE: 0.7422644211221808\n",
      "\n",
      "F1 SCORE: 0.7424716939443242\n",
      "\n",
      "F1 SCORE: 0.7427348571865556\n",
      "\n",
      "F1 SCORE: 0.7435031999142379\n",
      "\n",
      "F1 SCORE: 0.7439089875461701\n",
      "\n",
      "F1 SCORE: 0.7432703091279717\n",
      "\n",
      "F1 SCORE: 0.7433735197221749\n",
      "\n",
      "FINAL F1 SCORE: 0.7433735197221749\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n",
      "- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary.summary.weight', 'sequence_summary.summary.bias', 'logits_proj.bias', 'logits_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using custom data configuration default-4ec50749f179ee77\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /root/.cache/huggingface/datasets/csv/default-4ec50749f179ee77/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /root/.cache/huggingface/datasets/csv/default-4ec50749f179ee77/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b978705365b4176b82334ddec594772",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=31.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7446acc229c4dcca90b882bfa7ecc18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=31.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "F1 SCORE: 0.7665992633042944\n",
      "\n",
      "F1 SCORE: 0.7636768719974337\n",
      "\n",
      "F1 SCORE: 0.7584804590619623\n",
      "\n",
      "F1 SCORE: 0.7498461266624261\n",
      "\n",
      "F1 SCORE: 0.7473769722308944\n",
      "\n",
      "F1 SCORE: 0.7482110938310572\n",
      "\n",
      "F1 SCORE: 0.7490246500779861\n",
      "\n",
      "F1 SCORE: 0.7494148656918426\n",
      "\n",
      "F1 SCORE: 0.7459970183481958\n",
      "\n",
      "F1 SCORE: 0.74372650818062\n",
      "\n",
      "F1 SCORE: 0.7431533172420007\n",
      "\n",
      "F1 SCORE: 0.7411518431018567\n",
      "\n",
      "F1 SCORE: 0.7412261990368709\n",
      "\n",
      "F1 SCORE: 0.7421050933969322\n",
      "\n",
      "F1 SCORE: 0.7415495803558104\n",
      "\n",
      "F1 SCORE: 0.7410667223399965\n",
      "\n",
      "F1 SCORE: 0.7412122172323587\n",
      "\n",
      "F1 SCORE: 0.741187915094213\n",
      "\n",
      "F1 SCORE: 0.7417760462894067\n",
      "\n",
      "F1 SCORE: 0.7419942028837747\n",
      "\n",
      "F1 SCORE: 0.7420175952090722\n",
      "\n",
      "F1 SCORE: 0.7415520511372852\n",
      "\n",
      "F1 SCORE: 0.7428923670369996\n",
      "\n",
      "F1 SCORE: 0.743181007702952\n",
      "\n",
      "F1 SCORE: 0.7435194094331673\n",
      "\n",
      "F1 SCORE: 0.7443971877700503\n",
      "\n",
      "F1 SCORE: 0.7442429761166692\n",
      "\n",
      "F1 SCORE: 0.7440267649560776\n",
      "\n",
      "F1 SCORE: 0.743527161322397\n",
      "\n",
      "F1 SCORE: 0.7435026028225441\n",
      "\n",
      "F1 SCORE: 0.7437152626590623\n",
      "\n",
      "FINAL F1 SCORE: 0.7437152626590623\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n",
      "- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary.summary.weight', 'sequence_summary.summary.bias', 'logits_proj.bias', 'logits_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using custom data configuration default-952ac806a253cddb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /root/.cache/huggingface/datasets/csv/default-952ac806a253cddb/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /root/.cache/huggingface/datasets/csv/default-952ac806a253cddb/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab67e1fbf78d420abc7a03367d634dcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=31.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "293f1a485a9546bba16984b9d961249e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=31.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "F1 SCORE: 0.7429230098189668\n",
      "\n",
      "F1 SCORE: 0.7491153107631906\n",
      "\n",
      "F1 SCORE: 0.7398741218060998\n",
      "\n",
      "F1 SCORE: 0.7366680670690355\n",
      "\n",
      "F1 SCORE: 0.7375983103171209\n",
      "\n",
      "F1 SCORE: 0.7367346567512687\n",
      "\n",
      "F1 SCORE: 0.7392899286965432\n",
      "\n",
      "F1 SCORE: 0.7421085047368292\n",
      "\n",
      "F1 SCORE: 0.7425524858293469\n",
      "\n",
      "F1 SCORE: 0.7423893783740805\n",
      "\n",
      "F1 SCORE: 0.741290964106743\n",
      "\n",
      "F1 SCORE: 0.7429317185002455\n",
      "\n",
      "F1 SCORE: 0.7425893986674084\n",
      "\n",
      "F1 SCORE: 0.7444241980371107\n",
      "\n",
      "F1 SCORE: 0.7462377975880462\n",
      "\n",
      "F1 SCORE: 0.7451112087834051\n",
      "\n",
      "F1 SCORE: 0.7458944384740562\n",
      "\n",
      "F1 SCORE: 0.746812675848148\n",
      "\n",
      "F1 SCORE: 0.7451285841600953\n",
      "\n",
      "F1 SCORE: 0.7449047661185174\n",
      "\n",
      "F1 SCORE: 0.7451355268527248\n",
      "\n",
      "F1 SCORE: 0.7459700259244539\n",
      "\n",
      "F1 SCORE: 0.7456945791868005\n",
      "\n",
      "F1 SCORE: 0.7462521752909943\n",
      "\n",
      "F1 SCORE: 0.7453307183279897\n",
      "\n",
      "F1 SCORE: 0.7457611005817036\n",
      "\n",
      "F1 SCORE: 0.7457806312717241\n",
      "\n",
      "F1 SCORE: 0.745235536224377\n",
      "\n",
      "F1 SCORE: 0.7451694873858656\n",
      "\n",
      "F1 SCORE: 0.7456747827387142\n",
      "\n",
      "F1 SCORE: 0.7456971445381928\n",
      "\n",
      "FINAL F1 SCORE: 0.7456971445381928\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n",
      "- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary.summary.weight', 'sequence_summary.summary.bias', 'logits_proj.bias', 'logits_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using custom data configuration default-41d63c500ab7af5c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /root/.cache/huggingface/datasets/csv/default-41d63c500ab7af5c/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /root/.cache/huggingface/datasets/csv/default-41d63c500ab7af5c/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a71f796fa3454c2e9ad6d27248b8ff82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=31.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f035fcb1fe674a5bb737a8c0b855f4a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=31.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "F1 SCORE: 0.7437192627514955\n",
      "\n",
      "F1 SCORE: 0.7470739351658362\n",
      "\n",
      "F1 SCORE: 0.7398603957153606\n",
      "\n",
      "F1 SCORE: 0.742592551885368\n",
      "\n",
      "F1 SCORE: 0.743877489320211\n",
      "\n",
      "F1 SCORE: 0.7455653387478677\n",
      "\n",
      "F1 SCORE: 0.748119356079009\n",
      "\n",
      "F1 SCORE: 0.7465861364817309\n",
      "\n",
      "F1 SCORE: 0.7431873696112071\n",
      "\n",
      "F1 SCORE: 0.7444439712500568\n",
      "\n",
      "F1 SCORE: 0.7458345566090745\n",
      "\n",
      "F1 SCORE: 0.7461574182818822\n",
      "\n",
      "F1 SCORE: 0.7462475859043628\n",
      "\n",
      "F1 SCORE: 0.7474517624950613\n",
      "\n",
      "F1 SCORE: 0.7482391221147097\n",
      "\n",
      "F1 SCORE: 0.7493891841771696\n",
      "\n",
      "F1 SCORE: 0.7498511560451078\n",
      "\n",
      "F1 SCORE: 0.7504074777702798\n",
      "\n",
      "F1 SCORE: 0.7509660942418178\n",
      "\n",
      "F1 SCORE: 0.7506832195504619\n",
      "\n",
      "F1 SCORE: 0.7506263176184065\n",
      "\n",
      "F1 SCORE: 0.7499312996136446\n",
      "\n",
      "F1 SCORE: 0.7492229229109683\n",
      "\n",
      "F1 SCORE: 0.7490248840695335\n",
      "\n",
      "F1 SCORE: 0.7488515561527018\n",
      "\n",
      "F1 SCORE: 0.7493262635042469\n",
      "\n",
      "F1 SCORE: 0.7486715708778525\n",
      "\n",
      "F1 SCORE: 0.7485759626861933\n",
      "\n",
      "F1 SCORE: 0.7482115122561186\n",
      "\n",
      "F1 SCORE: 0.7487667055316762\n",
      "\n",
      "F1 SCORE: 0.7487299423522583\n",
      "\n",
      "FINAL F1 SCORE: 0.7487299423522583\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n",
      "- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary.summary.weight', 'sequence_summary.summary.bias', 'logits_proj.bias', 'logits_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using custom data configuration default-833d3dd3e2b6e9e0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /root/.cache/huggingface/datasets/csv/default-833d3dd3e2b6e9e0/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /root/.cache/huggingface/datasets/csv/default-833d3dd3e2b6e9e0/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "804d3836fded41aabe422191b48d9e4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=31.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b995adadaeea4f49868cf62f0e9ba23c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=31.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "F1 SCORE: 0.7479730526787047\n",
      "\n",
      "F1 SCORE: 0.7507885484704045\n",
      "\n",
      "F1 SCORE: 0.7513563853184965\n",
      "\n",
      "F1 SCORE: 0.7521428149061142\n",
      "\n",
      "F1 SCORE: 0.7549975270491388\n",
      "\n",
      "F1 SCORE: 0.7540600440765117\n",
      "\n",
      "F1 SCORE: 0.7549126221112671\n",
      "\n",
      "F1 SCORE: 0.7578435209055241\n",
      "\n",
      "F1 SCORE: 0.7590612941815089\n",
      "\n",
      "F1 SCORE: 0.7571638494253484\n",
      "\n",
      "F1 SCORE: 0.7554914175686633\n",
      "\n",
      "F1 SCORE: 0.7546620854848146\n",
      "\n",
      "F1 SCORE: 0.7544439219028498\n",
      "\n",
      "F1 SCORE: 0.7544474180729873\n",
      "\n",
      "F1 SCORE: 0.7542761223504189\n",
      "\n",
      "F1 SCORE: 0.7537798053480032\n",
      "\n",
      "F1 SCORE: 0.7542377915263115\n",
      "\n",
      "F1 SCORE: 0.7526311540701737\n",
      "\n",
      "F1 SCORE: 0.7523603655601825\n",
      "\n",
      "F1 SCORE: 0.7517848321494629\n",
      "\n",
      "F1 SCORE: 0.7532204110536727\n",
      "\n",
      "F1 SCORE: 0.7533294751953398\n",
      "\n",
      "F1 SCORE: 0.7518165975746587\n",
      "\n",
      "F1 SCORE: 0.7518952232485243\n",
      "\n",
      "F1 SCORE: 0.751996746078432\n",
      "\n",
      "F1 SCORE: 0.7524445085666767\n",
      "\n",
      "F1 SCORE: 0.752356705458871\n",
      "\n",
      "F1 SCORE: 0.7519716062350695\n",
      "\n",
      "F1 SCORE: 0.7513650177141584\n",
      "\n",
      "F1 SCORE: 0.7516984448768286\n",
      "\n",
      "F1 SCORE: 0.7518877864062338\n",
      "\n",
      "FINAL F1 SCORE: 0.7518877864062338\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from operator import truediv\n",
    "import numpy as np\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "files = glob(\"/model_saved/model_trained*\")\n",
    "text_column_name = \"reviewText\"\n",
    "FINAL_F1_SCORES = []\n",
    "\n",
    "\n",
    "for num, file in enumerate(files):\n",
    "    model = load_model_from_path(file)\n",
    "    lm_datasets = load_dataset_from_path(f\"data/data_test_sampled_for_drill_temp{num}.csv\")\n",
    "    results = []\n",
    "    labels = []\n",
    "    BATCH_SIZE = 256 * 4\n",
    "    with torch.no_grad():\n",
    "        for range_ in range(0, len(lm_datasets['train']), BATCH_SIZE):\n",
    "            x = lm_datasets['train'][range_:range_+BATCH_SIZE]\n",
    "            inputbatch = torch.tensor(x['input_ids']).to(model.transformer.device)\n",
    "            token_type_ids_batch = torch.tensor(x['token_type_ids']).to(model.transformer.device)\n",
    "            attention_mask = torch.tensor(x['attention_mask']).to(model.transformer.device)\n",
    "            labelbatch = torch.tensor(x['labels']).to(model.transformer.device)\n",
    "            output = model(inputbatch, attention_mask=attention_mask, token_type_ids=token_type_ids_batch, labels=labelbatch)\n",
    "            results.extend(torch.argmax(output.logits, dim=-1).detach().cpu().numpy().tolist())\n",
    "            labels.extend(labelbatch.cpu().detach().numpy().tolist())\n",
    "            f1 = f1_score([MAPPING[i] for i in labels], [MAPPING[i] for i in results], average='weighted')\n",
    "            print ('F1 SCORE: {}\\n'.format(f1))\n",
    "    f1 = f1_score([MAPPING[i] for i in labels], [MAPPING[i] for i in results], average='weighted')\n",
    "    print ('FINAL F1 SCORE: {}\\n'.format(f1))\n",
    "    FINAL_F1_SCORES.append(f1)\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5ececc43-8fd1-4fad-b4e3-5c70088315ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('roberta_scores.pkl', 'wb') as f:\n",
    "    pickle.dump(FINAL_F1_SCORES, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373530a1-75af-4bb1-9237-8a195f2f57ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
